{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4feb4f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574b07d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To verify; this function is suggested by copilot\n",
    "import unicodedata\n",
    "import string\n",
    "\n",
    "\n",
    "def comprehensive_character_scan(df, text_columns=None):\n",
    "    \"\"\"\n",
    "    Comprehensive scan of all characters with categorization\n",
    "    \"\"\"\n",
    "    if text_columns is None:\n",
    "        text_columns = [col for col in df.columns if df[col].dtype == \"object\"]\n",
    "\n",
    "    char_stats = {}\n",
    "\n",
    "    for col in text_columns:\n",
    "        for text in df[col].dropna():\n",
    "            text = str(text)\n",
    "            for char in text:\n",
    "                if char not in char_stats:\n",
    "                    char_stats[char] = {\n",
    "                        \"count\": 0,\n",
    "                        \"unicode_code\": ord(char),\n",
    "                        \"unicode_name\": unicodedata.name(char, \"UNKNOWN\"),\n",
    "                        \"category\": unicodedata.category(char),\n",
    "                        \"is_ascii\": ord(char) <= 127,\n",
    "                        \"is_printable\": char.isprintable(),\n",
    "                        \"columns\": set(),\n",
    "                    }\n",
    "                char_stats[char][\"count\"] += 1\n",
    "                char_stats[char][\"columns\"].add(col)\n",
    "\n",
    "    return char_stats\n",
    "\n",
    "\n",
    "# Run comprehensive scan\n",
    "char_analysis = comprehensive_character_scan(annotations_test)\n",
    "char_analysis.update(comprehensive_character_scan(labeled_dataset_test))\n",
    "\n",
    "# Categorize problematic characters\n",
    "categories = {\n",
    "    \"smart_quotes\": [],\n",
    "    \"dashes\": [],\n",
    "    \"spaces\": [],\n",
    "    \"symbols\": [],\n",
    "    \"accented\": [],\n",
    "    \"other_non_ascii\": [],\n",
    "}\n",
    "\n",
    "for char, stats in char_analysis.items():\n",
    "    if not stats[\"is_ascii\"]:\n",
    "        unicode_name = stats[\"unicode_name\"].lower()\n",
    "        if \"quote\" in unicode_name:\n",
    "            categories[\"smart_quotes\"].append((char, stats))\n",
    "        elif \"dash\" in unicode_name or \"hyphen\" in unicode_name:\n",
    "            categories[\"dashes\"].append((char, stats))\n",
    "        elif \"space\" in unicode_name:\n",
    "            categories[\"spaces\"].append((char, stats))\n",
    "        elif any(\n",
    "            accent in unicode_name\n",
    "            for accent in [\"acute\", \"grave\", \"circumflex\", \"tilde\", \"diaeresis\"]\n",
    "        ):\n",
    "            categories[\"accented\"].append((char, stats))\n",
    "        elif stats[\"category\"].startswith(\"S\"):  # Symbol categories\n",
    "            categories[\"symbols\"].append((char, stats))\n",
    "        else:\n",
    "            categories[\"other_non_ascii\"].append((char, stats))\n",
    "\n",
    "# Display results by category\n",
    "for category, chars in categories.items():\n",
    "    if chars:\n",
    "        print(f\"\\n=== {category.upper().replace('_', ' ')} ===\")\n",
    "        for char, stats in sorted(chars, key=lambda x: x[1][\"count\"], reverse=True):\n",
    "            print(\n",
    "                f\"'{char}' ({stats['unicode_code']:04x}) - {stats['unicode_name']} - Count: {stats['count']}\"\n",
    "            )\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
