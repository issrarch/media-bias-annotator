{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efb5156c",
   "metadata": {},
   "source": [
    "# Notebook 2: Target creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e39e4a",
   "metadata": {},
   "source": [
    "# (Ethical) News Engagement Prediction Model\n",
    "\n",
    "1. Business objective: \n",
    "    - Predict individual news engagement patterns and information\n",
    "    consumption preferences to enable:\n",
    "        - Personalized media literacy interventions\n",
    "        - Improved news content accessibility\n",
    "        - Evidence-based civic education programs\n",
    "        - Responsible platform design decisions\n",
    "\n",
    "2. Technical approach:\n",
    "    - Use demographic and media consumption data to predict internal engagement traits (political interest, news interest, avoidance behaviors, fatigue levels)\n",
    "\n",
    "3. Ethical framework: \n",
    "    - Promote information literacy and democratic participation\n",
    "    - Respect user privacy and autonomy\n",
    "    - Avoid exploitation or manipulation\n",
    "    - Support evidence-based interventions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee58d39a",
   "metadata": {},
   "source": [
    "### _Business value proposition_\n",
    "\n",
    "- For media companies:\n",
    "    - Understand audienc eengagement patterns\n",
    "    - Optimize content delivery strategies \n",
    "    - Improve user experience design \n",
    "    - Increase meaningful engagement\n",
    "\n",
    "- For educational organizations\n",
    "    - Target media literacy programs effectively\n",
    "    - Personalize civic education content\n",
    "    - Measure intervention success\n",
    "    - Allocate resources efficiently\n",
    "\n",
    "- For platforms and tech companies\n",
    "    - Design responsible recommendation systems\n",
    "    - Promote authoritative information sources\n",
    "    - Support informed user decision-making \n",
    "    - Enhance democratic discourse\n",
    "\n",
    "- For researchers and policymakers\n",
    "    - Evidence-based intervention design\n",
    "    - Population-level behavior insights\n",
    "    - Program evaluation metrics\n",
    "    - Democratic health indicators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c5d24a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "69df6cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the clean dataset from Notebook 01\n",
    "working_data = pd.read_csv(\"../data/processed/working_dataset_clean.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb812cb6",
   "metadata": {},
   "source": [
    "#### Quick memory optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "625fece7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Memory usage: 32.05 MB\n"
     ]
    }
   ],
   "source": [
    "# Show memory usage before conversion\n",
    "memory_before = working_data.memory_usage(deep=True).sum() / 1024**2\n",
    "print(f\"   Memory usage: {memory_before:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "57386c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Object columns: 24\n",
      "   country: 12 unique values\n",
      "   gender: 2 unique values\n",
      "   education: 10 unique values\n",
      "   income: 4 unique values\n",
      "   use_internet_general: 9 unique values\n",
      "   use_news_general: 9 unique values\n",
      "   use_news_main: 12 unique values\n",
      "   use_news_avoidance: 5 unique values\n",
      "   use_news_worn_out: 5 unique values\n",
      "   use_news_tvshows: 2 unique values\n",
      "   use_news_tvchannels: 2 unique values\n",
      "   use_news_radio: 2 unique values\n",
      "   use_news_newspapers_print: 2 unique values\n",
      "   use_news_magazines_print: 2 unique values\n",
      "   use_news_newspapers_online: 2 unique values\n",
      "   use_news_magazines_online: 2 unique values\n",
      "   use_news_broadcasting_online: 2 unique values\n",
      "   use_news_other_online: 2 unique values\n",
      "   use_news_sns: 2 unique values\n",
      "   use_news_blogs: 2 unique values\n",
      "   use_news_none: 2 unique values\n",
      "   interest_in_news: 6 unique values\n",
      "   interest_in_politics: 6 unique values\n",
      "   political_orientation: 8 unique values\n"
     ]
    }
   ],
   "source": [
    "# Show object columns\n",
    "object_cols = working_data.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "print(f\"   Object columns: {len(object_cols)}\")\n",
    "\n",
    "for col in object_cols:\n",
    "    print(f\"   {col}: {working_data[col].nunique()} unique values\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1a5e2ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert object columns (except uid) to category\n",
    "for col in object_cols:\n",
    "    if col != \"uid\":  # Keep uid as is (identifier)\n",
    "        working_data[col] = working_data[col].astype(\"category\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c0fec632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  uid: int64 (24,190 unique values)\n",
      "  country: category (12 unique values)\n",
      "  weight: float64 (2,914 unique values)\n",
      "  gender: category (2 unique values)\n",
      "  age: int64 (79 unique values)\n",
      "  education: category (10 unique values)\n",
      "  income: category (4 unique values)\n",
      "  use_internet_general: category (9 unique values)\n",
      "  use_news_general: category (9 unique values)\n",
      "  use_news_main: category (12 unique values)\n",
      "  use_news_avoidance: category (5 unique values)\n",
      "  use_news_worn_out: category (5 unique values)\n",
      "  use_news_tvshows: category (2 unique values)\n",
      "  use_news_tvchannels: category (2 unique values)\n",
      "  use_news_radio: category (2 unique values)\n",
      "  use_news_newspapers_print: category (2 unique values)\n",
      "  use_news_magazines_print: category (2 unique values)\n",
      "  use_news_newspapers_online: category (2 unique values)\n",
      "  use_news_magazines_online: category (2 unique values)\n",
      "  use_news_broadcasting_online: category (2 unique values)\n",
      "  use_news_other_online: category (2 unique values)\n",
      "  use_news_sns: category (2 unique values)\n",
      "  use_news_blogs: category (2 unique values)\n",
      "  use_news_none: category (2 unique values)\n",
      "  interest_in_news: category (6 unique values)\n",
      "  interest_in_politics: category (6 unique values)\n",
      "  political_orientation: category (8 unique values)\n"
     ]
    }
   ],
   "source": [
    "# Validate data types after conversion\n",
    "for col in working_data.columns:\n",
    "    dtype = working_data[col].dtype\n",
    "    unique_count = working_data[col].nunique()\n",
    "    print(f\"  {col}: {dtype} ({unique_count:,} unique values)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "79b5a6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Memory before conversion: 32.05 MB\n",
      "   Memory usage after conversion: 1.12 MB\n",
      "\n",
      "   Memory saved: 30.93 MB\n",
      "   Reduction: 96.5%\n"
     ]
    }
   ],
   "source": [
    "# Check memory usage after conversion\n",
    "memory_after = working_data.memory_usage(deep=True).sum() / 1024**2\n",
    "memory_saved = memory_before - memory_after\n",
    "memory_reduction = (memory_saved / memory_before) * 100\n",
    "\n",
    "print(f\"   Memory before conversion: {memory_before:.2f} MB\")\n",
    "print(f\"   Memory usage after conversion: {memory_after:.2f} MB\")\n",
    "print()\n",
    "print(f\"   Memory saved: {memory_saved:.2f} MB\")\n",
    "print(f\"   Reduction: {memory_reduction:.1f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "40dda128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types: {CategoricalDtype(categories=['No', 'Yes'], ordered=False, categories_dtype=object): 12, dtype('int64'): 2, CategoricalDtype(categories=['10+ times a day', '2-3 days a week', '2-5 times a day',\n",
      "                  '4-6 days a week', '6-10 times a day', 'don't know',\n",
      "                  'less than once a week', 'once a day', 'once a week'],\n",
      ", ordered=False, categories_dtype=object): 2, CategoricalDtype(categories=['don't know', 'extremely interested',\n",
      "                  'not at all interested', 'not very interested',\n",
      "                  'somewhat interested', 'very interested'],\n",
      ", ordered=False, categories_dtype=object): 2, CategoricalDtype(categories=['AT', 'AU', 'BR', 'DE', 'ES', 'JP', 'KR', 'NL', 'NO', 'RO',\n",
      "                  'UK', 'US'],\n",
      ", ordered=False, categories_dtype=object): 1, dtype('float64'): 1, CategoricalDtype(categories=['f', 'm'], ordered=False, categories_dtype=object): 1, CategoricalDtype(categories=['bachelors or equivalent', 'doctoral or equivalent',\n",
      "                  'early childhood', 'lower secondary',\n",
      "                  'masters or equivalent', 'none', 'post secondary', 'primary',\n",
      "                  'short-cycle tertiary', 'upper secondary'],\n",
      ", ordered=False, categories_dtype=object): 1, CategoricalDtype(categories=['Unknown', 'high', 'low', 'medium'], ordered=False, categories_dtype=object): 1, CategoricalDtype(categories=['24 hour news television channels', 'Blogs',\n",
      "                  'No main source', 'Printed Magazines', 'Printed Newspapers',\n",
      "                  'Radio news programmes or bulletins', 'Social media',\n",
      "                  'Television news bulletins or programmes',\n",
      "                  'Websites/apps of Newspapers',\n",
      "                  'Websites/apps of TV and Radio companies',\n",
      "                  'Websites/apps of news magazines',\n",
      "                  'Websites/apps of other news outlets'],\n",
      ", ordered=False, categories_dtype=object): 1, CategoricalDtype(categories=['don't know', 'never', 'occassionally', 'often',\n",
      "                  'sometimes'],\n",
      ", ordered=False, categories_dtype=object): 1, CategoricalDtype(categories=['neither agree nor disagree', 'strongly agree',\n",
      "                  'strongly disagree', 'tend to agree', 'tend to disagree'],\n",
      ", ordered=False, categories_dtype=object): 1, CategoricalDtype(categories=['centre', 'don't know', 'fairly left-wing',\n",
      "                  'fairly right-wing', 'slightly left-of-centre',\n",
      "                  'slightly right-of-centre', 'very left-wing',\n",
      "                  'very right-wing'],\n",
      ", ordered=False, categories_dtype=object): 1}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data types: {working_data.dtypes.value_counts().to_dict()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "40050fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Binary (Yes/No)     : 12 columns\n",
      "   Frequency scales    :  2 columns\n",
      "   Interest scales     :  2 columns\n",
      "   Country             :  1 columns\n",
      "   Gender              :  1 columns\n",
      "   Education           :  1 columns\n",
      "   Income              :  1 columns\n",
      "   News main source    :  1 columns\n",
      "   News avoidance      :  1 columns\n",
      "   News fatigue        :  1 columns\n",
      "   Political orientation:  1 columns\n",
      "   Numeric (int64)     :  2 columns\n",
      "   Numeric (float64)   :  1 columns\n",
      "    27 columns\n"
     ]
    }
   ],
   "source": [
    "dtype_summary = {\n",
    "    \"Binary (Yes/No)\": 12,\n",
    "    \"Frequency scales\": 2,\n",
    "    \"Interest scales\": 2,\n",
    "    \"Country\": 1,\n",
    "    \"Gender\": 1,\n",
    "    \"Education\": 1,\n",
    "    \"Income\": 1,\n",
    "    \"News main source\": 1,\n",
    "    \"News avoidance\": 1,\n",
    "    \"News fatigue\": 1,\n",
    "    \"Political orientation\": 1,\n",
    "    \"Numeric (int64)\": 2,\n",
    "    \"Numeric (float64)\": 1,\n",
    "}\n",
    "\n",
    "for dtype_name, count in dtype_summary.items():\n",
    "    print(f\"   {dtype_name:<20}: {count:>2} columns\")\n",
    "\n",
    "print(f\"    {sum(dtype_summary.values())} columns\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0c266e",
   "metadata": {},
   "source": [
    "# Explaining rationale behind target variable strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e4a354",
   "metadata": {},
   "source": [
    "## To avoid circular reasoning and data leakage\n",
    "\n",
    "- Research (e.g.: Pennycook & Rand (2019), Guess et al. (2020)) shows that  low political interest leads to reduced critical evaluation, thus, likely increasing a person's risk of being vulnerable to misinformation. \n",
    "- Meaning, if we are not careful about excluding attitude/interest variables from our target variable creation, this would bias the model because it will learn that correlation. \n",
    "\n",
    "- We _can_ help mitigate thus by establishing external ground truth and using external misinformation suceptibility measures such as behavioral measures like sharing fake news. We do have access to this information in Reuters' `usenews.mediacloud.2019` and `usenews.crowdtangle.2019` datasets, which capture actual media content and their associated engagement metrics (from 1.71 million Facebook posts). However, they are far too large for our current scale (~700MB and over 5GB, respectively). They would allow for much more sophisticated research insight, certainly. \n",
    "\n",
    "- Working within our constraints, we are instead maintaining strict separation of the attitute/interest variables, and instead creating the vulnerability score based on demographics and media consumption patterns alone. \n",
    "\n",
    "- As such, our division is as follows\n",
    "    - Target = Internal attitudes/traits\n",
    "    - Features = External behaviors/demographics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b526aee3",
   "metadata": {},
   "source": [
    "#### Separation of features and target variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ba442c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['interest_in_politics', 'interest_in_news', 'use_news_avoidance', 'use_news_worn_out', 'education']\n"
     ]
    }
   ],
   "source": [
    "# Separation of features and target variables\n",
    "\n",
    "# Target components (internal traits)\n",
    "target_components = [\n",
    "    \"interest_in_politics\",  # Political disengagement\n",
    "    \"interest_in_news\",  # News disengagement\n",
    "    \"use_news_avoidance\",  # Active news avoidance\n",
    "    \"use_news_worn_out\",  # News fatigue\n",
    "    \"education\",  # Media literacy proxy\n",
    "]\n",
    "\n",
    "print(target_components)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b64c8fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['country', 'gender', 'age', 'income', 'use_internet_general', 'use_news_general', 'use_news_main', 'use_news_tvshows', 'use_news_tvchannels', 'use_news_radio', 'use_news_newspapers_print', 'use_news_magazines_print', 'use_news_newspapers_online', 'use_news_magazines_online', 'use_news_broadcasting_online', 'use_news_other_online', 'use_news_sns', 'use_news_blogs', 'use_news_none']\n"
     ]
    }
   ],
   "source": [
    "# Predictive features (observable behaviors)\n",
    "feature_candidates = [\n",
    "    # Demographics (not attitudes)\n",
    "    \"country\",\n",
    "    \"gender\",\n",
    "    \"age\",\n",
    "    \"income\",\n",
    "    # Usage frequency (behavioral)\n",
    "    \"use_internet_general\",\n",
    "    \"use_news_general\",\n",
    "    # Main source choice (behavioral)\n",
    "    \"use_news_main\",\n",
    "    # Media channel usage (behavioral patterns)\n",
    "    \"use_news_tvshows\",\n",
    "    \"use_news_tvchannels\",\n",
    "    \"use_news_radio\",\n",
    "    \"use_news_newspapers_print\",\n",
    "    \"use_news_magazines_print\",\n",
    "    \"use_news_newspapers_online\",\n",
    "    \"use_news_magazines_online\",\n",
    "    \"use_news_broadcasting_online\",\n",
    "    \"use_news_other_online\",\n",
    "    \"use_news_sns\",\n",
    "    \"use_news_blogs\",\n",
    "    \"use_news_none\",\n",
    "]\n",
    "\n",
    "print(feature_candidates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f897d78f",
   "metadata": {},
   "source": [
    "## Vulnerability theory and scoring \n",
    "\n",
    "Based on research, the following factor seem to contribute heavily to misinformation vulnerability: \n",
    "\n",
    "1. Political disengagement\n",
    "    - Rationale: low political interest -> reduced critical evaluation\n",
    "    - Research: Pennycook, G., & Rand, D. G. (2019). Lazy, not biased: Susceptibility to partisan fake news is better explained by lack of reasoning than by motivated reasoning. Cognition, 188, 39–50. https://doi.org/10.1016/j.cognition.2018.06.011\n",
    "\n",
    "\n",
    "2. News disengagement\n",
    "    - Low news interest -> reduced information seeking\n",
    "    - Research: Prior, M. (2007). Post-Broadcast Democracy: How Media Choice Increases Inequality in Political Involvement and Polarizes Elections. Cambridge University Press. https://doi.org/10.1017/CBO9781139878425\n",
    "\n",
    "\n",
    "3. News avoidance \n",
    "    - Active avoidance -> information gaps\n",
    "    - Research: \n",
    "        - Toff, B., & Nielsen, R. K. (2018). “I Just Google It”: Folk Theories of Distributed Discovery. Journal of Communication, 68(3), 636–657. https://doi.org/10.1093/joc/jqy009\n",
    "        - Toff, B., & Nielsen, R. K. (2022). How News Feels: Anticipated Anxiety as a Factor in News Avoidance and a Barrier to Political Engagement. Political Communication, 39(6), 697–714. https://doi.org/10.1080/10584609.2022.2123073\n",
    "\n",
    "\n",
    "4. News fatigue \n",
    "    - Worn out by news -> reduced attention\n",
    "    - Research: Park, C. S. (2019). Does Too Much News on Social Media Discourage News Seeking? Mediating Role of News Efficacy Between Perceived News Overload and News Avoidance on Social Media. Social Media + Society, 5(3), 2056305119872956. https://doi.org/10.1177/2056305119872956\n",
    "\n",
    "\n",
    "5. Low education\n",
    "    - Reduced media literacy\n",
    "    - Research: Allcott, H., & Gentzkow, M. (2017). Social Media and Fake News in the 2016 Election. Journal of Economic Perspectives, 31(2), 211–236. https://doi.org/10.1257/jep.31.2.211\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b801997b",
   "metadata": {},
   "source": [
    "### Component weights based on research literature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9972d16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   political_disengagement: 25%\n",
      "   news_disengagement: 20%\n",
      "   news_avoidance: 20%\n",
      "   news_fatigue: 15%\n",
      "   education_vulnerability: 20%\n"
     ]
    }
   ],
   "source": [
    "# Component weights based on research literature\n",
    "vulnerability_weights = {\n",
    "    \"political_disengagement\": 0.25,  # Strongest predictor\n",
    "    \"news_disengagement\": 0.20,  # Core engagement\n",
    "    \"news_avoidance\": 0.20,  # Behavioral indicator\n",
    "    \"news_fatigue\": 0.15,  # Attention factor\n",
    "    \"education_vulnerability\": 0.20,  # Fundamental capability\n",
    "}\n",
    "\n",
    "\n",
    "for component, weight in vulnerability_weights.items():\n",
    "    print(f\"   {component}: {weight:.0%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3648f596",
   "metadata": {},
   "source": [
    "### Converting categorical responses to vulnerability scores (0-100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "805f2bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting categorical responses to vulnerability scores (0-100)\n",
    "\n",
    "# Political Interest → Political Disengagement (reversed)\n",
    "political_interest_map = {\n",
    "    \"extremely interested\": 0,\n",
    "    \"very interested\": 20,\n",
    "    \"somewhat interested\": 40,\n",
    "    \"not very interested\": 70,\n",
    "    \"not at all interested\": 100,\n",
    "    \"don't know\": 60,\n",
    "}\n",
    "\n",
    "# News Interest → News Disengagement (reversed)\n",
    "news_interest_map = {\n",
    "    \"extremely interested\": 0,\n",
    "    \"very interested\": 20,\n",
    "    \"somewhat interested\": 40,\n",
    "    \"not very interested\": 70,\n",
    "    \"not at all interested\": 100,\n",
    "    \"don't know\": 60,\n",
    "}\n",
    "\n",
    "# News Avoidance → Direct mapping\n",
    "news_avoidance_map = {\n",
    "    \"never\": 0,\n",
    "    \"occassionally\": 30,\n",
    "    \"sometimes\": 60,\n",
    "    \"often\": 100,\n",
    "    \"don't know\": 40,\n",
    "}\n",
    "\n",
    "# News Fatigue → Direct mapping (agreement = higher vulnerability)\n",
    "news_fatigue_map = {\n",
    "    \"strongly disagree\": 0,\n",
    "    \"tend to disagree\": 25,\n",
    "    \"neither agree nor disagree\": 50,\n",
    "    \"tend to agree\": 75,\n",
    "    \"strongly agree\": 100,\n",
    "}\n",
    "\n",
    "# Education → Education Vulnerability (reversed)\n",
    "education_map = {\n",
    "    \"doctoral or equivalent\": 0,\n",
    "    \"masters or equivalent\": 10,\n",
    "    \"bachelors or equivalent\": 20,\n",
    "    \"short-cycle tertiary\": 30,\n",
    "    \"post secondary\": 40,\n",
    "    \"upper secondary\": 50,\n",
    "    \"lower secondary\": 70,\n",
    "    \"primary\": 85,\n",
    "    \"early childhood\": 95,\n",
    "    \"none\": 100,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6eb037dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    interest_in_politics: All 6 categories mapped\n",
      "    interest_in_news: All 6 categories mapped\n",
      "    use_news_avoidance: All 5 categories mapped\n",
      "    use_news_worn_out: All 5 categories mapped\n",
      "    education: All 10 categories mapped\n"
     ]
    }
   ],
   "source": [
    "# Validate mappings cover all categories\n",
    "mappings_to_check = [\n",
    "    (\"interest_in_politics\", political_interest_map),\n",
    "    (\"interest_in_news\", news_interest_map),\n",
    "    (\"use_news_avoidance\", news_avoidance_map),\n",
    "    (\"use_news_worn_out\", news_fatigue_map),\n",
    "    (\"education\", education_map),\n",
    "]\n",
    "\n",
    "for var, mapping in mappings_to_check:\n",
    "    if var in working_data.columns:\n",
    "        categories = set(working_data[var].cat.categories)\n",
    "        mapped_categories = set(mapping.keys())\n",
    "        missing = categories - mapped_categories\n",
    "        if missing:\n",
    "            print(f\"    {var}: Missing mappings for {missing}\")\n",
    "        else:\n",
    "            print(f\"    {var}: All {len(categories)} categories mapped\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a35c73d",
   "metadata": {},
   "source": [
    "### Calculate vulnerability components based on mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7661e298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Political disengagement score calculated\n",
      "News disengagement score calculated\n",
      "News avoidance score calculated\n",
      "News fatigue score calculated\n",
      "Education vulnerability score calculated\n",
      "    political_disengagement_score: gucci\n",
      "    news_disengagement_score: gucci\n",
      "    news_avoidance_score: gucci\n",
      "    news_fatigue_score: gucci\n",
      "    education_vulnerability_score: gucci\n"
     ]
    }
   ],
   "source": [
    "# Calculate vulnerability components based on mappings\n",
    "\n",
    "# Component 1: Political Disengagement\n",
    "working_data[\"political_disengagement_score\"] = working_data[\n",
    "    \"interest_in_politics\"\n",
    "].map(political_interest_map)\n",
    "working_data[\"political_disengagement_score\"] = pd.to_numeric(\n",
    "    working_data[\"political_disengagement_score\"]\n",
    ")\n",
    "print(f\"Political disengagement score calculated\")\n",
    "\n",
    "# Component 2: News Disengagement\n",
    "working_data[\"news_disengagement_score\"] = working_data[\"interest_in_news\"].map(\n",
    "    news_interest_map\n",
    ")\n",
    "working_data[\"news_disengagement_score\"] = pd.to_numeric(\n",
    "    working_data[\"news_disengagement_score\"]\n",
    ")\n",
    "print(f\"News disengagement score calculated\")\n",
    "\n",
    "# Component 3: News Avoidance\n",
    "working_data[\"news_avoidance_score\"] = working_data[\"use_news_avoidance\"].map(\n",
    "    news_avoidance_map\n",
    ")\n",
    "working_data[\"news_avoidance_score\"] = pd.to_numeric(\n",
    "    working_data[\"news_avoidance_score\"]\n",
    ")\n",
    "print(f\"News avoidance score calculated\")\n",
    "\n",
    "# Component 4: News Fatigue\n",
    "working_data[\"news_fatigue_score\"] = working_data[\"use_news_worn_out\"].map(\n",
    "    news_fatigue_map\n",
    ")\n",
    "working_data[\"news_fatigue_score\"] = pd.to_numeric(working_data[\"news_fatigue_score\"])\n",
    "print(f\"News fatigue score calculated\")\n",
    "\n",
    "# Component 5: Education Vulnerability\n",
    "working_data[\"education_vulnerability_score\"] = working_data[\"education\"].map(\n",
    "    education_map\n",
    ")\n",
    "working_data[\"education_vulnerability_score\"] = pd.to_numeric(\n",
    "    working_data[\"education_vulnerability_score\"]\n",
    ")\n",
    "print(f\"Education vulnerability score calculated\")\n",
    "\n",
    "\n",
    "# Check for missing values in components\n",
    "component_cols = [\n",
    "    \"political_disengagement_score\",\n",
    "    \"news_disengagement_score\",\n",
    "    \"news_avoidance_score\",\n",
    "    \"news_fatigue_score\",\n",
    "    \"education_vulnerability_score\",\n",
    "]\n",
    "\n",
    "for col in component_cols:\n",
    "    missing = working_data[col].isnull().sum()\n",
    "    if missing > 0:\n",
    "        print(f\"    {col}: {missing} missing values\")\n",
    "    else:\n",
    "        print(f\"    {col}: gucci\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbdac6b",
   "metadata": {},
   "source": [
    "### Calculate composite vulnerability score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5c6ecdbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Composite vulnerability score calculated\n",
      "        Mean: 35.6\n",
      "        Std: 15.2\n",
      "        Min: 0.0\n",
      "        Max: 100.0\n",
      "        Median: 35.5\n"
     ]
    }
   ],
   "source": [
    "# Calculate weighted composite score\n",
    "working_data[\"vulnerability_score\"] = (\n",
    "    working_data[\"political_disengagement_score\"]\n",
    "    * vulnerability_weights[\"political_disengagement\"]\n",
    "    + working_data[\"news_disengagement_score\"]\n",
    "    * vulnerability_weights[\"news_disengagement\"]\n",
    "    + working_data[\"news_avoidance_score\"] * vulnerability_weights[\"news_avoidance\"]\n",
    "    + working_data[\"news_fatigue_score\"] * vulnerability_weights[\"news_fatigue\"]\n",
    "    + working_data[\"education_vulnerability_score\"]\n",
    "    * vulnerability_weights[\"education_vulnerability\"]\n",
    ")\n",
    "\n",
    "# Round to 1 decimal place for interpretability\n",
    "working_data[\"vulnerability_score\"] = working_data[\"vulnerability_score\"].round(1)\n",
    "\n",
    "\n",
    "print(f\"    Composite vulnerability score calculated\")\n",
    "print(f\"        Mean: {working_data['vulnerability_score'].mean():.1f}\")\n",
    "print(f\"        Std: {working_data['vulnerability_score'].std():.1f}\")\n",
    "print(f\"        Min: {working_data['vulnerability_score'].min():.1f}\")\n",
    "print(f\"        Max: {working_data['vulnerability_score'].max():.1f}\")\n",
    "print(f\"        Median: {working_data['vulnerability_score'].median():.1f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6ebb07",
   "metadata": {},
   "source": [
    "- Engagement levels\n",
    "\n",
    "    - Score 35.6: 'Medium-Low vulnerability'; 'Medium-High news engagement'\n",
    "    - Most people are reasonably engaged\n",
    "\n",
    "- Population insights\n",
    "\n",
    "    - Average person: Moderately engaged with news/politics\n",
    "    - Standard deviation: 15.2 points variation\n",
    "    - ~68% of people: 20.4 - 50.8 range (1 std)\n",
    "    - ~95% of people: 5.2 - 66.0 range (2 std)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f6737c",
   "metadata": {},
   "source": [
    "### Create risk categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4eff1fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define risk categories based on quartile-like thresholds\n",
    "def categorize_vulnerability(score):\n",
    "    if score < 25:\n",
    "        return \"Low\"\n",
    "    elif score < 50:\n",
    "        return \"Medium\"\n",
    "    elif score < 75:\n",
    "        return \"High\"\n",
    "    else:\n",
    "        return \"Very High\"\n",
    "\n",
    "\n",
    "working_data[\"vulnerability_category\"] = working_data[\"vulnerability_score\"].apply(\n",
    "    categorize_vulnerability\n",
    ")\n",
    "working_data[\"vulnerability_category\"] = working_data[\"vulnerability_category\"].astype(\n",
    "    \"category\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "62f9d653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RISK CATEGORY DISTRIBUTION:\n",
      "         Low:  6,037 ( 25.0%)\n",
      "      Medium: 14,056 ( 58.1%)\n",
      "        High:  3,855 ( 15.9%)\n",
      "   Very High:    242 (  1.0%)\n"
     ]
    }
   ],
   "source": [
    "# Set proper category order for plotting and analysis\n",
    "working_data[\"vulnerability_category\"] = working_data[\n",
    "    \"vulnerability_category\"\n",
    "].cat.reorder_categories([\"Low\", \"Medium\", \"High\", \"Very High\"])\n",
    "\n",
    "print(f\"RISK CATEGORY DISTRIBUTION:\")\n",
    "category_counts = working_data[\"vulnerability_category\"].value_counts()\n",
    "total_count = len(working_data)\n",
    "\n",
    "for category in [\"Low\", \"Medium\", \"High\", \"Very High\"]:\n",
    "    count = category_counts.get(category, 0)\n",
    "    pct = (count / total_count) * 100\n",
    "    print(f\"   {category:>9}: {count:>6,} ({pct:>5.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6f953d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population weighted statistics:\n",
      "   Weighted mean vulnerability: 36.0\n",
      "   Weighted std deviation: 15.2\n",
      "   Unweighted mean: 35.6\n",
      "   Unweighted std: 15.2\n",
      "   Mean difference: 0.4 points\n",
      "\n",
      "Weighted vs unweighted risk distribution:\n",
      "Category     Unweighted %  Weighted %  Difference\n",
      "--------------------------------------------------\n",
      "Low          25.0          24.2          -0.8\n",
      "Medium       58.1          58.3          +0.2\n",
      "High         15.9          16.5          +0.6\n",
      "Very High    1.0           1.0           +0.0\n",
      "\n",
      "Population weights show representative estimates\n"
     ]
    }
   ],
   "source": [
    "# Population weighted stats (using `weight` variable we saved earlier)\n",
    "\n",
    "if \"weight\" in working_data.columns:\n",
    "    # Calculate population-weighted vulnerability statistics\n",
    "    weighted_mean = np.average(\n",
    "        working_data[\"vulnerability_score\"], weights=working_data[\"weight\"]\n",
    "    )\n",
    "\n",
    "    # Calculate weighted standard deviation\n",
    "    weighted_variance = np.average(\n",
    "        (working_data[\"vulnerability_score\"] - weighted_mean) ** 2,\n",
    "        weights=working_data[\"weight\"],\n",
    "    )\n",
    "    weighted_std = np.sqrt(weighted_variance)\n",
    "\n",
    "    # Weighted category distribution\n",
    "    weighted_category_dist = {}\n",
    "    total_weight = working_data[\"weight\"].sum()\n",
    "\n",
    "    for category in [\"Low\", \"Medium\", \"High\", \"Very High\"]:\n",
    "        mask = working_data[\"vulnerability_category\"] == category\n",
    "        weighted_pct = (working_data.loc[mask, \"weight\"].sum() / total_weight) * 100\n",
    "        weighted_category_dist[category] = weighted_pct\n",
    "\n",
    "    print(f\"Population weighted statistics:\")\n",
    "    print(f\"   Weighted mean vulnerability: {weighted_mean:.1f}\")\n",
    "    print(f\"   Weighted std deviation: {weighted_std:.1f}\")\n",
    "    print(f\"   Unweighted mean: {working_data['vulnerability_score'].mean():.1f}\")\n",
    "    print(f\"   Unweighted std: {working_data['vulnerability_score'].std():.1f}\")\n",
    "    print(\n",
    "        f\"   Mean difference: {abs(weighted_mean - working_data['vulnerability_score'].mean()):.1f} points\"\n",
    "    )\n",
    "\n",
    "    print()\n",
    "    print(f\"Weighted vs unweighted risk distribution:\")\n",
    "    print(f\"{'Category':<12} {'Unweighted %':<13} {'Weighted %':<11} {'Difference'}\")\n",
    "    print(\"-\" * 50)\n",
    "    for category in [\"Low\", \"Medium\", \"High\", \"Very High\"]:\n",
    "        unweighted_pct = (category_counts.get(category, 0) / total_count) * 100\n",
    "        weighted_pct = weighted_category_dist[category]\n",
    "        diff = weighted_pct - unweighted_pct\n",
    "        print(\n",
    "            f\"{category:<12} {unweighted_pct:<13.1f} {weighted_pct:<11.1f} {diff:>+6.1f}\"\n",
    "        )\n",
    "\n",
    "    print()\n",
    "    print(f\"Population weights show representative estimates\")\n",
    "\n",
    "else:\n",
    "    print(f\"No survey weights available - using unweighted statistics\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8025f0aa",
   "metadata": {},
   "source": [
    "### Feature-Target Separation Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7ebfd88a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target components (separated from features):\n",
      "   1. interest_in_politics\n",
      "   2. interest_in_news\n",
      "   3. use_news_avoidance\n",
      "   4. use_news_worn_out\n",
      "   5. education\n"
     ]
    }
   ],
   "source": [
    "# Feature-Target Separation Validation\n",
    "\n",
    "# Target components (excluded from features)\n",
    "target_components = [\n",
    "    \"interest_in_politics\",  # Political disengagement\n",
    "    \"interest_in_news\",  # News disengagement\n",
    "    \"use_news_avoidance\",  # Active news avoidance\n",
    "    \"use_news_worn_out\",  # News fatigue\n",
    "    \"education\",  # Media literacy proxy\n",
    "]\n",
    "\n",
    "print(f\"target components (separated from features):\")\n",
    "for i, comp in enumerate(target_components, 1):\n",
    "    print(f\"   {i}. {comp}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6bfed564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature candidates:\n",
      "    Demographics: country, gender, age, income\n",
      "    Usage patterns: use_internet_general, use_news_general\n",
      "    Main source: use_news_main\n",
      "    Media channels: 12 channel variables\n",
      "    Total features: 19 variables\n"
     ]
    }
   ],
   "source": [
    "# Feature candidates (for ML model)\n",
    "feature_candidates = [\n",
    "    # Demographics (not attitudes)\n",
    "    \"country\",\n",
    "    \"gender\",\n",
    "    \"age\",\n",
    "    \"income\",\n",
    "    # Usage frequency (behavioral)\n",
    "    \"use_internet_general\",\n",
    "    \"use_news_general\",\n",
    "    # Main source choice (behavioral)\n",
    "    \"use_news_main\",\n",
    "    # Media channel usage (behavioral patterns)\n",
    "    \"use_news_tvshows\",\n",
    "    \"use_news_tvchannels\",\n",
    "    \"use_news_radio\",\n",
    "    \"use_news_newspapers_print\",\n",
    "    \"use_news_magazines_print\",\n",
    "    \"use_news_newspapers_online\",\n",
    "    \"use_news_magazines_online\",\n",
    "    \"use_news_broadcasting_online\",\n",
    "    \"use_news_other_online\",\n",
    "    \"use_news_sns\",\n",
    "    \"use_news_blogs\",\n",
    "    \"use_news_none\",\n",
    "]\n",
    "\n",
    "print(f\"Feature candidates:\")\n",
    "print(f\"    Demographics: country, gender, age, income\")\n",
    "print(f\"    Usage patterns: use_internet_general, use_news_general\")\n",
    "print(f\"    Main source: use_news_main\")\n",
    "print(\n",
    "    f\"    Media channels: {len([f for f in feature_candidates if 'use_news_' in f and f != 'use_news_general' and f != 'use_news_main'])} channel variables\"\n",
    ")\n",
    "print(f\"    Total features: {len(feature_candidates)} variables\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c95d34ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excluded variable (too close to target):\n",
      "   • political_orientation (similar to political interest)\n"
     ]
    }
   ],
   "source": [
    "# Variables excluded for being too close to target\n",
    "excluded_vars = [\"political_orientation\"]  # Too similar to political interest\n",
    "print(f\"Excluded variable (too close to target):\")\n",
    "for var in excluded_vars:\n",
    "    print(f\"   • {var} (similar to political interest)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57281149",
   "metadata": {},
   "source": [
    "### Validation checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "4867e538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separation validation:\n",
      "    No overlap between target and feature variables\n",
      "    All target components present in dataset\n",
      "    All feature candidates present in dataset\n",
      "    Clean separation maintained\n"
     ]
    }
   ],
   "source": [
    "# Validation checks\n",
    "print(f\"Separation validation:\")\n",
    "overlap = set(target_components) & set(feature_candidates)\n",
    "if overlap:\n",
    "    print(f\"    Overlap detected: {overlap}\")\n",
    "else:\n",
    "    print(f\"    No overlap between target and feature variables\")\n",
    "\n",
    "# Check all target components exist\n",
    "missing_target_components = [\n",
    "    comp for comp in target_components if comp not in working_data.columns\n",
    "]\n",
    "if missing_target_components:\n",
    "    print(f\"    Missing target components: {missing_target_components}\")\n",
    "else:\n",
    "    print(f\"    All target components present in dataset\")\n",
    "\n",
    "# Check all feature candidates exist\n",
    "missing_feature_candidates = [\n",
    "    feat for feat in feature_candidates if feat not in working_data.columns\n",
    "]\n",
    "if missing_feature_candidates:\n",
    "    print(f\"    Missing feature candidates: {missing_feature_candidates}\")\n",
    "else:\n",
    "    print(f\"    All feature candidates present in dataset\")\n",
    "\n",
    "print(f\"    Clean separation maintained\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059349ee",
   "metadata": {},
   "source": [
    "## Checkpoint: Saving dataset with target variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "30b7ad6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main dataset saved: dataset_with_target.csv\n"
     ]
    }
   ],
   "source": [
    "working_data.to_csv(\"../data/processed/dataset_with_target.csv\", index=False)\n",
    "print(\"Main dataset saved: dataset_with_target.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe502b46",
   "metadata": {},
   "source": [
    "# Initial feature engineering (simple transformation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f73185",
   "metadata": {},
   "source": [
    "### Create feature-only dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "92df79ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature dataset created: (24190, 19)\n",
      "No missing values in feature candidates\n"
     ]
    }
   ],
   "source": [
    "# Create feature-only dataset\n",
    "feature_data = working_data[feature_candidates].copy()\n",
    "print(f\"Feature dataset created: {feature_data.shape}\")\n",
    "\n",
    "# Check for missing values in features\n",
    "missing_summary = feature_data.isnull().sum()\n",
    "features_with_missing = missing_summary[missing_summary > 0]\n",
    "\n",
    "if len(features_with_missing) > 0:\n",
    "    print(\"Features with missing values:\")\n",
    "    for feature, count in features_with_missing.items():\n",
    "        pct = (count / len(feature_data)) * 100\n",
    "        print(f\"  {feature}: {count} ({pct:.1f}%)\")\n",
    "else:\n",
    "    print(\"No missing values in feature candidates\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96c8ebf",
   "metadata": {},
   "source": [
    "### Categorical encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fe12d319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical features to encode: 18\n",
      "Binary features (Yes/No): 12\n",
      "  use_news_tvshows -> use_news_tvshows_binary\n",
      "  use_news_tvchannels -> use_news_tvchannels_binary\n",
      "  use_news_radio -> use_news_radio_binary\n",
      "  use_news_newspapers_print -> use_news_newspapers_print_binary\n",
      "  use_news_magazines_print -> use_news_magazines_print_binary\n",
      "  use_news_newspapers_online -> use_news_newspapers_online_binary\n",
      "  use_news_magazines_online -> use_news_magazines_online_binary\n",
      "  use_news_broadcasting_online -> use_news_broadcasting_online_binary\n",
      "  use_news_other_online -> use_news_other_online_binary\n",
      "  use_news_sns -> use_news_sns_binary\n",
      "  use_news_blogs -> use_news_blogs_binary\n",
      "  use_news_none -> use_news_none_binary\n"
     ]
    }
   ],
   "source": [
    "#  Categorical encoding\n",
    "\n",
    "# Identify categorical features\n",
    "categorical_features = []\n",
    "for col in feature_candidates:\n",
    "    if col in feature_data.columns and feature_data[col].dtype == \"category\":\n",
    "        categorical_features.append(col)\n",
    "\n",
    "print(f\"Categorical features to encode: {len(categorical_features)}\")\n",
    "\n",
    "# Binary encoding for Yes/No variables\n",
    "binary_features = []\n",
    "for col in categorical_features:\n",
    "    unique_vals = feature_data[col].cat.categories.tolist()\n",
    "    if set(unique_vals) == {\"Yes\", \"No\"} or set(unique_vals) == {\"No\", \"Yes\"}:\n",
    "        binary_features.append(col)\n",
    "\n",
    "print(f\"Binary features (Yes/No): {len(binary_features)}\")\n",
    "\n",
    "# Apply binary encoding\n",
    "for col in binary_features:\n",
    "    feature_data[f\"{col}_binary\"] = (feature_data[col] == \"Yes\").astype(int)\n",
    "    print(f\"  {col} -> {col}_binary\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659356b4",
   "metadata": {},
   "source": [
    "### Ordinal encoding for ordered categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b929907a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    income -> income_ordinal (ordinal)\n"
     ]
    }
   ],
   "source": [
    "# Ordinal encoding for ordered categories\n",
    "ordinal_features = []\n",
    "\n",
    "# Income is ordinal\n",
    "if \"income\" in categorical_features:\n",
    "    income_order = [\"low\", \"medium\", \"high\", \"Unknown\"]\n",
    "    income_mapping = {level: i for i, level in enumerate(income_order)}\n",
    "    feature_data[\"income_ordinal\"] = feature_data[\"income\"].map(income_mapping)\n",
    "    ordinal_features.append(\"income\")\n",
    "    print(f\"    income -> income_ordinal (ordinal)\")\n",
    "\n",
    "# Education is ordinal\n",
    "if \"education\" in categorical_features:\n",
    "    education_order = [\n",
    "        \"none\",\n",
    "        \"primary\",\n",
    "        \"early childhood\",\n",
    "        \"lower secondary\",\n",
    "        \"upper secondary\",\n",
    "        \"post secondary\",\n",
    "        \"short-cycle tertiary\",\n",
    "        \"bachelors or equivalent\",\n",
    "        \"masters or equivalent\",\n",
    "        \"doctoral or equivalent\",\n",
    "    ]\n",
    "    education_mapping = {level: i for i, level in enumerate(education_order)}\n",
    "    feature_data[\"education_ordinal\"] = feature_data[\"education\"].map(education_mapping)\n",
    "    ordinal_features.append(\"education\")\n",
    "    print(f\"    education -> education_ordinal (ordinal)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca583fd",
   "metadata": {},
   "source": [
    "### One-hot encoding for nominal categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "12136ed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nominal features for one-hot encoding: 5\n",
      "  country -> 12 dummy variables\n",
      "  gender -> 2 dummy variables\n",
      "  use_internet_general -> 9 dummy variables\n",
      "  use_news_general -> 9 dummy variables\n",
      "  use_news_main -> 12 dummy variables\n",
      "One-hot encoded features: (24190, 44)\n"
     ]
    }
   ],
   "source": [
    "# One-hot encoding for nominal categories\n",
    "nominal_features = [\n",
    "    col\n",
    "    for col in categorical_features\n",
    "    if col not in binary_features and col not in ordinal_features\n",
    "]\n",
    "\n",
    "print(f\"Nominal features for one-hot encoding: {len(nominal_features)}\")\n",
    "\n",
    "# Apply one-hot encoding\n",
    "encoded_dfs = []\n",
    "for col in nominal_features:\n",
    "    # Create one-hot encoded columns\n",
    "    dummies = pd.get_dummies(feature_data[col], prefix=col, prefix_sep=\"_\")\n",
    "    encoded_dfs.append(dummies)\n",
    "    print(f\"  {col} -> {dummies.shape[1]} dummy variables\")\n",
    "\n",
    "# Combine all encoded features\n",
    "if encoded_dfs:\n",
    "    encoded_features = pd.concat(encoded_dfs, axis=1)\n",
    "    print(f\"One-hot encoded features: {encoded_features.shape}\")\n",
    "else:\n",
    "    encoded_features = pd.DataFrame(index=feature_data.index)\n",
    "    print(\"No nominal features to one-hot encode\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9934b26",
   "metadata": {},
   "source": [
    "### Numeric feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4cdc7800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age is already numeric, but create age groups as additional feature\n",
    "if \"age\" in feature_data.columns:\n",
    "    feature_data[\"age_group\"] = pd.cut(\n",
    "        feature_data[\"age\"],\n",
    "        bins=[0, 30, 45, 60, 100],\n",
    "        labels=[\"18-30\", \"31-45\", \"46-60\", \"60+\"],\n",
    "    )\n",
    "    # Convert age groups to dummy variables\n",
    "    age_dummies = pd.get_dummies(feature_data[\"age_group\"], prefix=\"age_group\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010869e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media usage features created:\n",
      "  total_media_channels\n",
      "  traditional_media_count (5 channels)\n",
      "  digital_media_count (6 channels)\n"
     ]
    }
   ],
   "source": [
    "# Create media usage count features\n",
    "media_usage_cols = [\n",
    "    col for col in binary_features if \"use_news_\" in col and col != \"use_news_general\"\n",
    "]\n",
    "if media_usage_cols:\n",
    "    # Count total media channels used\n",
    "    media_usage_binary = feature_data[[f\"{col}_binary\" for col in media_usage_cols]]\n",
    "    feature_data[\"total_media_channels\"] = media_usage_binary.sum(axis=1)\n",
    "\n",
    "    # Traditional vs digital media usage\n",
    "    traditional_cols = [\n",
    "        col\n",
    "        for col in media_usage_cols\n",
    "        if any(x in col for x in [\"tv\", \"radio\", \"print\"])\n",
    "    ]\n",
    "    digital_cols = [\n",
    "        col\n",
    "        for col in media_usage_cols\n",
    "        if any(x in col for x in [\"online\", \"sns\", \"blogs\"])\n",
    "    ]\n",
    "\n",
    "    if traditional_cols:\n",
    "        traditional_binary = feature_data[[f\"{col}_binary\" for col in traditional_cols]]\n",
    "        feature_data[\"traditional_media_count\"] = traditional_binary.sum(axis=1)\n",
    "\n",
    "    if digital_cols:\n",
    "        digital_binary = feature_data[[f\"{col}_binary\" for col in digital_cols]]\n",
    "        feature_data[\"digital_media_count\"] = digital_binary.sum(axis=1)\n",
    "\n",
    "    print(f\"Media usage features created:\")\n",
    "    print(f\"  total_media_channels\")\n",
    "    print(f\"  traditional_media_count ({len(traditional_cols)} channels)\")\n",
    "    print(f\"  digital_media_count ({len(digital_cols)} channels)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7b8947",
   "metadata": {},
   "source": [
    "### Combine all engineered features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "fa7fd510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final engineered features: (24190, 65)\n",
      "Feature types:\n",
      "  Numeric: 1\n",
      "  Binary: 12\n",
      "  Ordinal: 1\n",
      "  One-hot: 44\n",
      "  Age groups: 4\n",
      "  Usage counts: 3\n"
     ]
    }
   ],
   "source": [
    "# Combine all engineered features\n",
    "\n",
    "# Collect all engineered features\n",
    "engineered_features = []\n",
    "\n",
    "# Original numeric features\n",
    "numeric_features = [\"age\"] if \"age\" in feature_data.columns else []\n",
    "if numeric_features:\n",
    "    engineered_features.append(feature_data[numeric_features])\n",
    "\n",
    "# Binary encoded features\n",
    "binary_encoded_cols = [f\"{col}_binary\" for col in binary_features]\n",
    "if binary_encoded_cols:\n",
    "    engineered_features.append(feature_data[binary_encoded_cols])\n",
    "\n",
    "# Ordinal encoded features\n",
    "ordinal_encoded_cols = []\n",
    "if \"income\" in ordinal_features:\n",
    "    ordinal_encoded_cols.append(\"income_ordinal\")\n",
    "if \"education\" in ordinal_features:\n",
    "    ordinal_encoded_cols.append(\"education_ordinal\")\n",
    "if ordinal_encoded_cols:\n",
    "    engineered_features.append(feature_data[ordinal_encoded_cols])\n",
    "\n",
    "# One-hot encoded features\n",
    "if not encoded_features.empty:\n",
    "    engineered_features.append(encoded_features)\n",
    "\n",
    "# Age group dummies\n",
    "if not age_dummies.empty:\n",
    "    engineered_features.append(age_dummies)\n",
    "\n",
    "# Media usage count features\n",
    "usage_count_cols = []\n",
    "if \"total_media_channels\" in feature_data.columns:\n",
    "    usage_count_cols.append(\"total_media_channels\")\n",
    "if \"traditional_media_count\" in feature_data.columns:\n",
    "    usage_count_cols.append(\"traditional_media_count\")\n",
    "if \"digital_media_count\" in feature_data.columns:\n",
    "    usage_count_cols.append(\"digital_media_count\")\n",
    "if usage_count_cols:\n",
    "    engineered_features.append(feature_data[usage_count_cols])\n",
    "\n",
    "# Combine all features\n",
    "if engineered_features:\n",
    "    final_features = pd.concat(engineered_features, axis=1)\n",
    "else:\n",
    "    final_features = pd.DataFrame(index=feature_data.index)\n",
    "\n",
    "print(f\"Final engineered features: {final_features.shape}\")\n",
    "print(f\"Feature types:\")\n",
    "print(f\"  Numeric: {len(numeric_features)}\")\n",
    "print(f\"  Binary: {len(binary_encoded_cols)}\")\n",
    "print(f\"  Ordinal: {len(ordinal_encoded_cols)}\")\n",
    "print(f\"  One-hot: {encoded_features.shape[1] if not encoded_features.empty else 0}\")\n",
    "print(f\"  Age groups: {age_dummies.shape[1] if not age_dummies.empty else 0}\")\n",
    "print(f\"  Usage counts: {len(usage_count_cols)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cad8746",
   "metadata": {},
   "source": [
    "## Create final dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb4f243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survey weight included (for statistics only)\n"
     ]
    }
   ],
   "source": [
    "# Combine features with target variable\n",
    "final_dataset = final_features.copy()\n",
    "final_dataset[\"vulnerability_score\"] = working_data[\"vulnerability_score\"]\n",
    "final_dataset[\"vulnerability_category\"] = working_data[\"vulnerability_category\"]\n",
    "\n",
    "# Add weight column (for population statistics)\n",
    "if \"weight\" in working_data.columns:\n",
    "    final_dataset[\"weight\"] = working_data[\"weight\"]\n",
    "    print(\"Survey weight included (for statistics only)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "552a3d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing values in final dataset\n"
     ]
    }
   ],
   "source": [
    "# Check for any remaining missing values\n",
    "missing_final = final_dataset.isnull().sum()\n",
    "features_with_missing_final = missing_final[missing_final > 0]\n",
    "\n",
    "if len(features_with_missing_final) > 0:\n",
    "    print(\"Warning: Missing values in final dataset:\")\n",
    "    for feature, count in features_with_missing_final.items():\n",
    "        pct = (count / len(final_dataset)) * 100\n",
    "        print(f\"  {feature}: {count} ({pct:.1f}%)\")\n",
    "else:\n",
    "    print(\"No missing values in final dataset\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c3de4237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save engineered dataset\n",
    "final_dataset.to_csv(\"../data/processed/dataset_engineered.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_summer_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
